## LOAD CAMVID ##
from load_camvid import make_x2y, make_rgb2label, make_set

# Create a Dictionary of filenames that maps input x to labels y
x_dir = './ML-Datasets/CamVid/701_StillsRaw_full'
y_dir = './ML-Datasets/CamVid/LabeledApproved_full'
x2y = make_x2y(x_dir,y_dir)

# Create a Dictionary to convert rgb data to labeled data
rgb2label = make_rgb2label('./ML-Datasets/CamVid/label_colors.txt')

# Get the training, validation and test sets
train_files = make_set("./ML-Datasets/CamVid/train.txt")
val_files = make_set("./ML-Datasets/CamVid/val.txt")
test_files = make_set("./ML-Datasets/CamVid/test.txt")

## BUILD MODEL ##
from model import calibration_softmax, relu6, mobilenetV2
model = mobilenetV2(input_shape=(720, 960, 3), classes=12, alpha=1., reg=0.0001, d=0.1)
model.summary()

## DEFINE METRICS AND WEIGHTS LOSS FUNCTION ##
from metrics import MeanIoU, IoU, single_class_accuracy
import numpy as np

num_classes = 12
miou_metric = MeanIoU(num_classes)
void_iou_metric = IoU(num_classes,0)
sky_iou_metric = IoU(num_classes,1)
building_iou_metric = IoU(num_classes,2)
pole_iou_metric = IoU(num_classes,3)
road_iou_metric = IoU(num_classes,4)
pavement_iou_metric = IoU(num_classes,5)
tree_iou_metric = IoU(num_classes,6)
sign_iou_metric = IoU(num_classes,7)
fence_iou_metric = IoU(num_classes,8)
car_iou_metric = IoU(num_classes,9)
pedestrian_iou_metric = IoU(num_classes,10)
cyclist_iou_metric = IoU(num_classes,11)

void_acc_metric = single_class_accuracy(0)
sky_acc_metric = single_class_accuracy(1)
building_acc_metric = single_class_accuracy(2)
pole_acc_metric = single_class_accuracy(3)
road_acc_metric = single_class_accuracy(4)
pavement_acc_metric = single_class_accuracy(5)
tree_acc_metric = single_class_accuracy(6)
sign_acc_metric = single_class_accuracy(7)
fence_acc_metric = single_class_accuracy(8)
car_acc_metric = single_class_accuracy(9)
pedestrian_acc_metric = single_class_accuracy(10)
cyclist_acc_metric = single_class_accuracy(11)

# weights when using median frequency balancing used in SegNet paper
# https://arxiv.org/pdf/1511.00561.pdf
# The numbers were generated by:
# https://github.com/yandex/segnet-torch/blob/master/datasets/camvid-gen.lua

weights = np.array([0,
                    0.58872014284134,
                    0.51052379608154,
                    2.6966278553009,
                    0.45021694898605,
                    1.1785038709641,
                    0.77028578519821,
                    2.4782588481903,
                    2.5273461341858,
                    1.0122526884079,
                    3.2375309467316,
                    4.1312313079834])

## COMPILE MODEL ##
from losses import weighted_categorical_crossentropy
import numpy as np
import keras

# Define Loss and Optimizer
model.compile(
    loss=weighted_categorical_crossentropy(weights),
    optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),
    metrics=['accuracy',
             miou_metric.mean_iou,
             void_iou_metric.iou,
             sky_iou_metric.iou,
             building_iou_metric.iou,
             pole_iou_metric.iou,
             road_iou_metric.iou,
             pavement_iou_metric.iou,
             tree_iou_metric.iou,
             sign_iou_metric.iou,
             fence_iou_metric.iou,
             car_iou_metric.iou,
             pedestrian_iou_metric.iou,
             cyclist_iou_metric.iou,
             void_acc_metric,
             sky_acc_metric,
             building_acc_metric,
             pole_acc_metric,
             road_acc_metric,
             pavement_acc_metric,
             tree_acc_metric,
             sign_acc_metric,
             fence_acc_metric,
             car_acc_metric,
             pedestrian_acc_metric,
             cyclist_acc_metric])

## LOAD WEIGHTS ##
from keras.models import load_model
name = 'baseline_weights' #Change this name to load the best model
model.load_weights("./{}.h5".format(name))

## EVALUATE MODEL ##
# from sequence import generate_data

# X,y = generate_data(test_files[0:1],1,x2y,rgb2label,x_dir,y_dir).__getitem__(0)
# test_accuracy = model.evaluate(X,y)
# print(test_accuracy)

model.layers.pop()
i = model.input
o = model.layers[-1].output
model = keras.models.Model(inputs=i, outputs=[o])

model.compile(
    loss=weighted_categorical_crossentropy(weights),
    optimizer=keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),
    metrics=['accuracy',
             miou_metric.mean_iou,
             void_iou_metric.iou,
             sky_iou_metric.iou,
             building_iou_metric.iou,
             pole_iou_metric.iou,
             road_iou_metric.iou,
             pavement_iou_metric.iou,
             tree_iou_metric.iou,
             sign_iou_metric.iou,
             fence_iou_metric.iou,
             car_iou_metric.iou,
             pedestrian_iou_metric.iou,
             cyclist_iou_metric.iou,
             void_acc_metric,
             sky_acc_metric,
             building_acc_metric,
             pole_acc_metric,
             road_acc_metric,
             pavement_acc_metric,
             tree_acc_metric,
             sign_acc_metric,
             fence_acc_metric,
             car_acc_metric,
             pedestrian_acc_metric,
             cyclist_acc_metric])

from sequence import generate_data

# Define the batch to analyze
files = test_files + val_files
batch_size = 1

count_one = np.zeros((10,))
total = np.zeros((10,))
i = 0
image_data = generate_data(files,batch_size,x2y,rgb2label,x_dir,y_dir)
for (x,y) in image_data:
  # flatten ground truth
  y = np.reshape(y,(batch_size*720*960*12,))

  # compute logits of prediction over image x
  prediction = model.predict(x,steps=1)

  # make T equal to 1 to get uncalibrated probabilities
  T = 1

  # compute softmax of logits and flatten
  uncalibrated = calibration_softmax(prediction/(T))
  uncalibrated = np.reshape(uncalibrated,(batch_size*720*960*12))

  # flatten logits
  prediction = np.reshape(prediction,(batch_size*720*960*12))

  # trim all values close to zero
  new_uncalibrated = (((1+(uncalibrated >= 0.005))-1) * uncalibrated)
  new_y = y[new_uncalibrated!=0]
  new_uncalibrated = new_uncalibrated[new_uncalibrated!=0]

  # fill bins
  range_min = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
  range_max = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]

  for j in range(10):
    cropped_pred = new_uncalibrated[new_uncalibrated < range_max[j]]
    cropped_y = new_y[new_uncalibrated < range_max[j]]
    bin_sample = cropped_y[cropped_pred > range_min[j]]
    count_one[j] = count_one[j] + np.count_nonzero(bin_sample)
    total[j] = total[j] + len(bin_sample)

  i = i + 1
  print(i)
  print(count_one/total)

true = [0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95]
print("count_one =", count_one)
print("total =", total)
p = count_one/total
print("p =", p)

# MSE
print("MSE = {:.5f}".format(np.sum((p-true)**2)/len(true)))

# ECE
print("ECE = {:.5f}".format(np.sum((total/np.sum(total))*np.abs(p-true))))

# MCE
print("MCE = {:.5f}".format(np.max(np.abs(p-true))))
